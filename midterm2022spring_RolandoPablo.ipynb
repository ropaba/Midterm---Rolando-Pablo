{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"https://jsantarc.github.io/ADMN5016_2022/images/logo-stc.jpeg\" width=\"300\" alt=\"cognitiveclass.ai logo\"  />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Midterm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify the Iris flower dataset using Logistic Regression   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Iris flower data set or Fisher's Iris data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis.[1] It is sometimes called Anderson's Iris data set because Edgar Anderson collected the data to quantify the morphologic variation of Iris flowers of three related species.[2] Two of the three species were collected in the GaspÃ© Peninsula \"all from the same pasture, and picked on the same day and measured at the same time by the same person with the same apparatus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following 5 questions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's install `seaborn` for visualization tasks and import required libaries for this lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn==0.11.1 in c:\\users\\rorpa\\anaconda3\\lib\\site-packages (0.11.1)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\rorpa\\anaconda3\\lib\\site-packages (from seaborn==0.11.1) (1.7.3)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\rorpa\\anaconda3\\lib\\site-packages (from seaborn==0.11.1) (1.4.2)\n",
      "Requirement already satisfied: matplotlib>=2.2 in c:\\users\\rorpa\\anaconda3\\lib\\site-packages (from seaborn==0.11.1) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\rorpa\\anaconda3\\lib\\site-packages (from seaborn==0.11.1) (1.21.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\rorpa\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn==0.11.1) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rorpa\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn==0.11.1) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\rorpa\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn==0.11.1) (3.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rorpa\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn==0.11.1) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rorpa\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn==0.11.1) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\rorpa\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn==0.11.1) (9.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rorpa\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn==0.11.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rorpa\\anaconda3\\lib\\site-packages (from pandas>=0.23->seaborn==0.11.1) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rorpa\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn==0.11.1) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn==0.11.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and explore the tumor sample dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(Q-1)</b>  load the dataset `iris.csv` as a Pandas dataframe with ```read_csv```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read datast in csv format\n",
    "dataset_url = \"https://raw.githubusercontent.com/jsantarc/ADMN5016_2022/master/week-1/iris.csv\"\n",
    "df = pd.read_csv(dataset_url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(Q-2)</b> split the dataframe  into input `X` with columns <code>'sepal_length','sepal_width','petal_length','petal_width'</code> and output `y` and column  <code>'species'</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =df[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y = df['species']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(Q-3)</b>  split  dataset <code>X</code> and <code>y</code> into a training and  testing datasets with the following using ```train_test_split```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size=0.2\n",
    "random_state=0\n",
    "#train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 80% as training dataset\n",
    "# and 20% as testing dataset (we can also use this as Validation data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(Q-4)</b> Create a k-nearest neighbor object setting K=4 and fit it using the training  data ```KNeighborsClassifier```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(Q-5)</b> Test the  k-nearest neighbor  object and fit it using test data : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['virginica', 'versicolor', 'setosa', 'virginica', 'setosa',\n",
       "       'virginica', 'setosa', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'setosa', 'versicolor', 'versicolor', 'setosa',\n",
       "       'setosa', 'virginica', 'versicolor', 'setosa', 'setosa',\n",
       "       'versicolor', 'setosa', 'setosa', 'versicolor', 'versicolor',\n",
       "       'setosa'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = knn_model.predict(X_test)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more check out my course on <a href=\"https://www.coursera.org/learn/machine-learning-with-python\">Machine Learning with Python</a> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
